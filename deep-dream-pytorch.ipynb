{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep-Dream Pytorch implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup instructions\n",
    "* Install Conda\n",
    "https://www.anaconda.com/download/#macos\n",
    "\n",
    "* Install pytorch and torchvision (computer vision for pytorch) package\n",
    "\n",
    "`conda install pytorch torchvision -c pytorch`\n",
    "\n",
    "https://pytorch.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "* https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html \n",
    "* https://en.wikipedia.org/wiki/DeepDream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "* https://github.com/sar-gupta/deep-dream-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python imports\n",
    "* torch, numpy, torchvision\n",
    "* PIL: Python Imaging Library\n",
    "* pyplot: plotting image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import glob\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "from PIL import Image, ImageFilter, ImageChops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Program configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_ENABLED = False\n",
    "\n",
    "# Deep dream configs\n",
    "LAYER_ID = 28 # The layer to maximize the activations through\n",
    "NUM_ITERATIONS = 5 # Number of iterations to update the input image with the layer's gradient\n",
    "LR = 0.2\n",
    "\n",
    "# We downscale the image recursively, apply the deep dream computation, scale up, and then blend with the original image \n",
    "# to achieve better result.\n",
    "NUM_DOWNSCALES = 20\n",
    "BLEND_ALPHA = 0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DeepDream class: use a vgg16 pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepDream:\n",
    "    def __init__(self, image):\n",
    "        self.image = image\n",
    "        self.model = models.vgg16(pretrained=False)\n",
    "        if CUDA_ENABLED:\n",
    "            self.model = self.model.cuda()\n",
    "        self.modules = list(self.model.features.modules())\n",
    "        \n",
    "        # vgg16 use 224x224 images\n",
    "        imgSize = 224\n",
    "        self.transformMean = [0.485, 0.456, 0.406]\n",
    "        self.transformStd = [0.229, 0.224, 0.225]\n",
    "        self.transformNormalise = transforms.Normalize(\n",
    "            mean=self.transformMean,\n",
    "            std=self.transformStd\n",
    "        )\n",
    "        \n",
    "        self.transformPreprocess = transforms.Compose([\n",
    "            transforms.Resize((imgSize, imgSize)),\n",
    "            transforms.ToTensor(),\n",
    "            self.transformNormalise\n",
    "        ])\n",
    "        \n",
    "        self.tensorMean = torch.Tensor(self.transformMean)\n",
    "        if CUDA_ENABLED:\n",
    "            self.tensorMean = self.tensorMean.cuda()\n",
    "\n",
    "        self.tensorStd = torch.Tensor(self.transformStd)\n",
    "        if CUDA_ENABLED:\n",
    "            self.tensorStd = self.tensorStd.cuda()\n",
    "\n",
    "    def toImage(self, input):\n",
    "        return input * self.tensorStd + self.tensorMean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main deep dream algorithm\n",
    "Input \n",
    "* an input image\n",
    "* layerId\n",
    "* number of iterations\n",
    "\n",
    "Makes a forward pass until layerId, computes the gradient and updates the input image. This is repeated for the given number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepDream(DeepDream):\n",
    "    def deepDream(self, image, layer, iterations, lr):\n",
    "        transformed = self.transformPreprocess(image).unsqueeze(0)\n",
    "        if CUDA_ENABLED:\n",
    "            transformed = transformed.cuda()\n",
    "        input = torch.autograd.Variable(transformed, requires_grad=True)\n",
    "        self.model.zero_grad()\n",
    "        for _ in range(iterations):\n",
    "            out = input\n",
    "            for layerId in range(layer):\n",
    "                out = self.modules[layerId + 1](out)\n",
    "            loss = out.norm()\n",
    "            loss.backward()\n",
    "            input.data = input.data + lr * input.grad.data\n",
    "\n",
    "        input = input.data.squeeze()\n",
    "        input.transpose_(0,1)\n",
    "        input.transpose_(1,2)\n",
    "        input = np.clip(self.toImage(input), 0, 1)\n",
    "        return Image.fromarray(np.uint8(input*255))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursively apply deepDream at different scales and blend the result images to make the final image looks better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepDream(DeepDream):\n",
    "    def deepDreamRecursive(self, image, layer, iterations, lr, num_downscales):\n",
    "        if num_downscales > 0:\n",
    "            # scale down the image\n",
    "            image_small = image.filter(ImageFilter.GaussianBlur(2))\n",
    "            small_size = (int(image.size[0]/2), int(image.size[1]/2))            \n",
    "            if (small_size[0] == 0 or small_size[1] == 0):\n",
    "                small_size = image.size\n",
    "            image_small = image_small.resize(small_size, Image.ANTIALIAS)\n",
    "            \n",
    "            # run deepDreamRecursive on the scaled down image\n",
    "            image_small = self.deepDreamRecursive(image_small, layer, iterations, lr, num_downscales-1)\n",
    "            \n",
    "            # Scale up the result image to the original size\n",
    "            image_large = image_small.resize(image.size, Image.ANTIALIAS)\n",
    "            \n",
    "            # Blend the two image\n",
    "            image = ImageChops.blend(image, image_large, BLEND_ALPHA)\n",
    "        img_result = self.deepDream(image, layer, iterations, lr)\n",
    "        img_result = img_result.resize(image.size)\n",
    "        return img_result\n",
    "    \n",
    "    def deepDreamProcess(self):\n",
    "        return self.deepDreamRecursive(self.image, LAYER_ID, NUM_ITERATIONS, LR, NUM_DOWNSCALES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it will load each image and perform \"deep dream\" on it. Note that the computation could take a few minutes each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "processing image: deepdream_starry_night.jpg\n"
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'PosixPath' object has no attribute 'absolutePath'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-84328709bf33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjpgFilePaths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"processing image: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mdreamImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-60-84328709bf33>\u001b[0m in \u001b[0;36mdreamImage\u001b[0;34m(jpgPath)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjpgPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Image loaded from \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mjpgPath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabsolutePath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mdreamedImage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDeepDream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepDreamProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdreamedImage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PosixPath' object has no attribute 'absolutePath'"
     ]
    }
   ],
   "source": [
    "sourcesFolder = Path(\"./source_images\")\n",
    "dreamedFolder = Path(\"./dreamed_images\")\n",
    "jpgFilePaths = []\n",
    "\n",
    "for filePath in sourcesFolder.glob(\"*.jpg\"):\n",
    "    jpgFilePaths.append(Path(filePath))\n",
    "\n",
    "def dreamImage(jpgPath):\n",
    "    image = Image.open(jpgPath)\n",
    "    pyplot.imshow(image)\n",
    "    pyplot.title(\"Image loaded from \" + str(jpgPath))\n",
    "    dreamedImage = DeepDream(image).deepDreamProcess()\n",
    "    pyplot.imshow(dreamedImage)\n",
    "    pyplot.title(\"Deep dreamed image\")\n",
    "    dreamedImage.save(dreamedFolder / ('deepdreamed-' + jpgPath.name))    \n",
    "\n",
    "for path in jpgFilePaths:\n",
    "    print(\"processing image: \" + path.name)\n",
    "    dreamImage(path)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}